{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "constitutional-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder,OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier\n",
    "from sklearn.linear_model import Lasso, LogisticRegression, LinearRegression\n",
    "from sklearn.feature_selection import SelectFromModel, RFE\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn import svm\n",
    "import category_encoders as ce\n",
    "\n",
    "from multiprocessing import Process,Pool\n",
    "import copy\n",
    "import time\n",
    "import os\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "confirmed-brush",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = ['C_VEHS', 'A_DAGE', 'A_PERS', 'A_VAGE']\n",
    "categorical_features = ['C_MNTH', 'C_WDAY', 'A_CHUR', 'C_CONF', 'C_RCFG', 'C_WTHR','C_RSUR','C_RALN','C_TRAF','V_TYPE','A_DSEX','P_SAFE']\n",
    "\n",
    "dtypes = {}\n",
    "for feature in numeric_features:\n",
    "    dtypes[feature] = 'float' \n",
    "for feature in categorical_features:\n",
    "    dtypes[feature] = 'str' \n",
    "\n",
    "data = pd.read_csv('crash_transformed.csv',dtype=dtypes,)\n",
    "#data[categorical_features] = data[categorical_features].astype('category')\n",
    "#data[numeric_features] = data[numeric_features].astype('float64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "palestinian-synthetic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C_MNTH': dtype('O'),\n",
       " 'C_WDAY': dtype('O'),\n",
       " 'A_CHUR': dtype('O'),\n",
       " 'C_SEV': dtype('int64'),\n",
       " 'C_VEHS': dtype('float64'),\n",
       " 'C_CONF': dtype('O'),\n",
       " 'C_RCFG': dtype('O'),\n",
       " 'C_WTHR': dtype('O'),\n",
       " 'C_RSUR': dtype('O'),\n",
       " 'C_RALN': dtype('O'),\n",
       " 'C_TRAF': dtype('O'),\n",
       " 'V_TYPE': dtype('O'),\n",
       " 'A_DSEX': dtype('O'),\n",
       " 'A_DAGE': dtype('float64'),\n",
       " 'P_SAFE': dtype('O'),\n",
       " 'A_PERS': dtype('float64'),\n",
       " 'A_VAGE': dtype('float64')}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ranking-representation",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('C_SEV',axis=1)\n",
    "y = data['C_SEV']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "manual-speech",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "appointed-magazine",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())])\n",
    "\n",
    "one_hot_categories = ['C_MNTH', 'C_WDAY', 'A_CHUR', 'A_DSEX']\n",
    "cat_boost_categories = ['C_CONF', 'C_RCFG', 'C_WTHR','C_RSUR','C_RALN','C_TRAF','V_TYPE','P_SAFE']\n",
    "\n",
    "categorical_transformer_one_hot = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "categorical_transformer_cat_boost = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('encoder', ce.CatBoostEncoder())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "downtown-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat1', categorical_transformer_one_hot, one_hot_categories),\n",
    "        ('cat2', categorical_transformer_one_hot, cat_boost_categories)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "coupled-notification",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'n_jobs'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-123-f6919daf17de>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                \u001b[0mRandomForestClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                \u001b[0mLinearRegression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                svm.SVC(n_jobs=-1)]\n\u001b[0m",
      "\u001b[1;32mF:\\Anaconda\\envs\\python37v2\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'n_jobs'"
     ]
    }
   ],
   "source": [
    "#SelectFromModel(, threshold = 0.08)\n",
    "classifiers = [LogisticRegression(C=1, penalty='l1', solver='liblinear',n_jobs=-1),\n",
    "               RandomForestClassifier(n_jobs=-1),\n",
    "               LinearRegression(n_jobs=-1),\n",
    "               svm.SVC()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "labeled-model",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda\\envs\\python37v2\\lib\\site-packages\\sklearn\\pipeline.py:296: UserWarning: Persisting input arguments took 93.71s to run.\n",
      "If this happens often in your code, it can cause performance problems \n",
      "(results will be correct in all cases). \n",
      "The reason for this is probably some large input arguments for a wrapped\n",
      " function (e.g. large strings).\n",
      "THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an\n",
      " example so that they can fix the problem.\n",
      "  **fit_params_steps[name])\n",
      "F:\\Anaconda\\envs\\python37v2\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1355: UserWarning: 'n_jobs' > 1 does not have any effect when 'solver' is set to 'liblinear'. Got 'n_jobs' = 24.\n",
      "  \" = {}.\".format(effective_n_jobs(self.n_jobs)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train duration 1226.3494708538055\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SelectFromModel' object has no attribute 'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-764dadf0a1ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpipe\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpipelines\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mfit_pipeline\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;31m#fit_pipeline(pipelines[1],X_train, X_test, y_train, y_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-124-764dadf0a1ec>\u001b[0m in \u001b[0;36mfit_pipeline\u001b[1;34m(pipe, xtrain, xtest, ytrain, ytest)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'train duration {(time.time() - start_time)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"model score: %.3f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mytest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'classifier'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.txt'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m         \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Model '\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnamed_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'classifier'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Anaconda\\envs\\python37v2\\lib\\site-packages\\sklearn\\utils\\metaestimators.py\u001b[0m in \u001b[0;36m__get__\u001b[1;34m(self, obj, type)\u001b[0m\n\u001b[0;32m    111\u001b[0m                     \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m                     \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattribute_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SelectFromModel' object has no attribute 'score'"
     ]
    }
   ],
   "source": [
    "pipelines = []\n",
    "        \n",
    "for classifier in classifiers:\n",
    "    pipelines.append(\n",
    "        Pipeline(steps = [('preprocessor', preprocessor),('classifier',classifier)],memory='./cache'))\n",
    "\n",
    "\n",
    "def fit_pipeline(pipe,xtrain,xtest,ytrain,ytest):\n",
    "    start_time = time.time()\n",
    "    print('Training started')\n",
    "    pipe.fit(xtrain, ytrain)\n",
    "    print(f'train duration {(time.time() - start_time)}')\n",
    "    print(\"model score: %.3f\" % pipe.score(xtest, ytest))\n",
    "    with open(str(pipe.named_steps['classifier'])[:15]+'.txt', 'w') as f:\n",
    "        f.write('Model '+str(pipe.named_steps['classifier']))\n",
    "        f.write('\\n')\n",
    "        f.write(f'train duration {(time.time() - start_time)}')\n",
    "        f.write('\\n')\n",
    "        f.write(\"model score: %.3f\" % pipe.score(xtest, ytest))\n",
    "        \n",
    "for pipe in pipelines:\n",
    "    fit_pipeline(pipe,X_train, X_test, y_train, y_test)\n",
    "#fit_pipeline(pipelines[1],X_train, X_test, y_train, y_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "utility-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "threading = False\n",
    "\n",
    "if threading:\n",
    "    threads = []\n",
    "    for pipe in pipelines:\n",
    "        t = threading.Thread(target=fit_pipeline,args=pipe)\n",
    "        threads.append(t)\n",
    "        t.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "first-throw",
   "metadata": {},
   "outputs": [],
   "source": [
    "parallelize = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "labeled-trauma",
   "metadata": {},
   "outputs": [],
   "source": [
    "if parallelize:\n",
    "    from nbmultitask import ProcessWithLogAndControls\n",
    "    from multiprocessing import Value\n",
    "    # !pip install --user nbmultitask\n",
    "    tasks = []\n",
    "    for pipe in pipelines:\n",
    "        tasks.append(ProcessWithLogAndControls(target=fit_pipeline, args=pipe))\n",
    "    tasks[0].control_panel()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-clearance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
